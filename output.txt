2nd experiment:
A: 1000111110010001101010111101100110101101100010110001111011010011101001001011100101001010111000111010
B: 0111000001101110010101000010011001010010011101001110000100101100010110110100011010110101000111000101
1st Won/Lost: 6
Middle value: 0.06
2nd Won/Lost: -6
Middle value: -0.06
Theoretical result for A: 0.00000
Standart deviation: 0.060000
Variance: 0.001800
3rd experiment:
A: 1101111001010010110101011110000101001000001010100010101011001110110000001111011010101001001010111110
B: 0010000110101101001010100001111010110111110101011101010100110001001111110000100101010110110101000001
1st Won/Lost: -28
Middle value: -0.28
2nd Won/Lost: 28
Middle value: 0.28
Theoretical result for A: -0.25000
Standart deviation: 0.375366
Variance: 0.000450
4.1 - reinforcement learning:
A: 0010000100110110011101100010001101110100010110101100010111010111101001011011011011010101100000000000
B: 1101111011001001100010011101110010001011101001010011101000101000010110100100100100101010011111111111
1st Won/Lost: 7
Middle value: 0.07
2nd Won/Lost: -7
Middle value: -0.07
Theoretical result for A: 0.23684
Standart deviation: 0.246970
Variance: 0.013918
4.2 - learning with punishment:
A: 1101100101001000111000110001001101010101110000001001101100110010000111000110101101011010010010111110
B: 0010011010110111000111001110110010101010001111110110010011001101111000111001010010100101101101000001
1st Won/Lost: 30
Middle value: 0.30
2nd Won/Lost: -30
Middle value: -0.30
Theoretical result for A: 0.72222
Standart deviation: 0.782052
Variance: 0.089136
4.3 - learning both players with reinforcement:
A: 0110001010101011111010011011101111101111111111010001001111111011111011001111111110111101011111101111
B: 1001110101010100000101100100010000010000000000101110110000000100000100110000000001000010100000010000
1st Won/Lost: 88
Middle value: 0.88
2nd Won/Lost: -88
Middle value: -0.88
Theoretical result for A: -0.01657
Standart deviation: 0.880156
Variance: 0.401918
